Simplified Prompt Series: Temporal 3D Scene Graph with Robotics (M1 Mac + Thunder Compute)
STEP 0: Download or Record Video Data
Get short videos of objects being moved on a table. Use datasets like Ego4D or EPIC-KITCHENS, or record your own with your phone. Save videos in `data/raw_videos/`.
STEP 1: Set Up Project Folders
Create folders for data, tracking, segmentation, 3D reconstruction, scene graphs, robotics simulation, and LLM prompts. Use a `main.py` to control the pipeline.
STEP 2: Detect and Track Objects
Use YOLO latest compatible version for object detection and ByteTrack to assign object IDs across frames. Save bounding boxes per frame in JSON format.
STEP 3: Segment Objects
Use SAM to generate segmentation masks for each tracked object. Save masks and associate them with tracked object IDs.
STEP 4: 3D Reconstruction with COLMAP
Extract frames and run COLMAP on Thunder Compute to get camera poses. Triangulate object positions from masks and camera info. Save 3D positions for each object.
STEP 5: Build Scene Graph
Use NetworkX to create a graph where nodes are objects and edges represent spatial/temporal interactions like �next to�, �picked up�, etc.
STEP 6: Interpret Graph with LLM
Use DeepSeek R1 to summarize the scene or generate action plans based on the graph, like �Clear the table.� Return structured robot tasks.
STEP 7: Simulate Robot Actions
Use PyBullet to simulate a robot arm picking and placing objects as instructed by the LLM. Place objects at their 3D coordinates.
STEP 8: Export Results
Save a report with simulation results, object movements, and LLM summary. Export videos and JSON logs for evaluation.
